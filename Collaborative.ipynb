{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Recommendations\n",
    "\n",
    "In this notebook we're going to build a collaborative recommendation algorithm for our knitting data (kindly provided by www.ravelry.com)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from collections import Counter\n",
    "from scipy.sparse import hstack\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from math import log, sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've made these csvs publically available in an s3 bucket, here:\n",
    "\n",
    "You can go and download that and put it in a directory of your choice - you'll need to change the path in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/recommend/user_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns_df = pd.read_csv('../data/recommend/patterns_data.csv')\n",
    "patterns_df.index = patterns_df.pattern_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Not much to do here - just gonna filter to only patterns with 5 or more likes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df.groupby('pattern_id')['user_id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[df.pattern_id.map(counts) >= 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a matrix of user likes\n",
    "\n",
    "What were going to do here is turn the data into a \"matrix\" - one row for each pattern, and one column for every user. Each cell holds either a one - if the user likes that pattern - or a zero if they don't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           6910\n",
       "1          16783\n",
       "2          16783\n",
       "3          16783\n",
       "4          16783\n",
       "5          16783\n",
       "6          16783\n",
       "7          14485\n",
       "8          14485\n",
       "9          17394\n",
       "10         17394\n",
       "11         17394\n",
       "12         17394\n",
       "13         17394\n",
       "14         17394\n",
       "15         17394\n",
       "16         17394\n",
       "17         17394\n",
       "18         17394\n",
       "19         17394\n",
       "20         17394\n",
       "21         17394\n",
       "22         17394\n",
       "23         17394\n",
       "24         17394\n",
       "25         17394\n",
       "26         17394\n",
       "27         17394\n",
       "28         17394\n",
       "29         17394\n",
       "           ...  \n",
       "3756684     8101\n",
       "3756685     8101\n",
       "3756686     8101\n",
       "3756687     8101\n",
       "3756688     8101\n",
       "3756689     8101\n",
       "3756690     8101\n",
       "3756691     8101\n",
       "3756692     8101\n",
       "3756693     8101\n",
       "3756694     8101\n",
       "3756695     8101\n",
       "3756696     8101\n",
       "3756697     8101\n",
       "3756698     8101\n",
       "3756699     8101\n",
       "3756700     8101\n",
       "3756701     8101\n",
       "3756702     8101\n",
       "3756703     8101\n",
       "3756704     8101\n",
       "3756705     8101\n",
       "3756706     8101\n",
       "3756707     8101\n",
       "3756708     8101\n",
       "3756709     8101\n",
       "3756710     8101\n",
       "3756711     8101\n",
       "3756712     8101\n",
       "3756713     8101\n",
       "Length: 3756714, dtype: int16"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_matrix(df):\n",
    "    data = np.ones(len(df))\n",
    "    col = pd.Series(pd.Categorical(df.user_id)).cat.codes\n",
    "    row = pd.Series(pd.Categorical(df.pattern_id)).cat.codes\n",
    "    return csr_matrix((data, (row, col)), shape=(df.pattern_id.nunique(), df.user_id.nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = make_matrix(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're also gonna \"TFIDF transform\" the data - this reduces the effect of \"super users\" who have liked a whole lot of stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer()\n",
    "matrix = transformer.fit_transform(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Dimensionality reduction\n",
    "\n",
    "This is a bit complicated, but we're going to use an algorithm to reduce the dimensionality of the data - that is, turn it from one column per user to only 35 columns, while retaining as much information as possible. This is a way of \"smoothing\" the data - weird outliers tend to be reduced, and you get more consistent results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrinky = TruncatedSVD(35, random_state=6) \n",
    "\n",
    "# SVD is a stochastic algorithm, so I've fixed the random state to ensure consistent results. \n",
    "# Many of the patterns have similar profiles, so a different random state gives slightly different recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrunk = shrinky.fit_transform(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding similar patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a bit fiddly converting from the matrix (which contains one row for each pattern with five or more likes) back to the DataFrame which has the pattern names, but the process is otherwise simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = list(filtered_df.pattern_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_ids = patterns_df.pattern_id\n",
    "pattern_ids.index = patterns_df.permalink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = patterns.index(pattern_ids.loc['mr-dangly'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how Mr. Dangly looks in our shrunk matrix: just 35 values which define what kinds of users like him, and what kinds don't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0895207 ,  0.02946681, -0.0574579 , -0.03167866, -0.0509617 ,\n",
       "        0.01118265,  0.01919036, -0.02228885,  0.01880677,  0.02909504,\n",
       "       -0.01188873, -0.00646529, -0.0389338 , -0.0470142 , -0.01109375,\n",
       "        0.00856811, -0.00951299,  0.00711156, -0.00357397,  0.00124073,\n",
       "        0.02102683, -0.00951941, -0.02167144, -0.0024223 , -0.00691445,\n",
       "        0.00731288, -0.00792361, -0.01751737, -0.04219167,  0.0106009 ,\n",
       "        0.00480203,  0.02572602, -0.01532836, -0.02027218, -0.01442943])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shrunk[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding similar patterns is just a simple euclidean distance calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "similars = [products[n] for n in pd.Series([i[0] for i in \\\n",
    "                        pairwise_distances(shrunk, shrunk[target].reshape(1, -1), metric='cosine')]).argsort()[:10].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mr-dangly',\n",
       " 'socktopus',\n",
       " 'robot-hat-2',\n",
       " 'the-great-batsby',\n",
       " 'misty-morn-gloves',\n",
       " 'the-thrifty-critter',\n",
       " 'felted-knit-amigurumi-kitties',\n",
       " 'praying-mantis',\n",
       " 'pasha',\n",
       " 'cthulhuclava']"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[patterns_df.permalink.loc[i] for i in similars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
